group_by(Publication.Year) %>%
summarize(total = sum(n))
year_title_counts <- left_join(year_title_words, year_total_words)
ggplot(year_title_counts, aes(n/total, fill = Publication.Year)) +
geom_histogram(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free_y")
top5_values_year <- year_title_counts %>%
group_by(Publication.Year) %>%
arrange(desc(n)) %>%
slice_head(n = 5) %>%
ungroup()
table(top5_values_year$Publication.Year, top5_values_year$word)
year_tf_idf <- year_title_counts %>%
bind_tf_idf(word, Publication.Year, n)
year_tf_idf %>%
select(-total) %>%
arrange(desc(tf_idf))
top5_year_tf_idf <- year_tf_idf %>%
group_by(Publication.Year) %>%
arrange(desc(tf_idf)) %>%
slice_head(n = 5) %>%
ungroup()
# Visualizing top 5 words in title per year
top5_year_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf_idf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
top5_year_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf, fct_reorder(word, tf), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "tf", y = NULL)
nrc_neg <- get_sentiments("nrc") %>%
filter(sentiment == "negative")
nrc_pos <- get_sentiments("nrc") %>%
filter(sentiment == "positive")
neg = data_filtered %>%
inner_join(nrc_neg) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
pos = data_filtered %>%
inner_join(nrc_pos) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts <- data_filtered %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
data_filtered %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("gray20", "gray80"),
max.words = 100)
jane_austen_sentiment <- data_filtered %>%
inner_join(get_sentiments("bing")) %>%
count(Publication.Year, index = row_number() %/% 40, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(jane_austen_sentiment, aes(index, sentiment, fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free_x")
test = title_counts %>%
cast_dtm(DOI, word, n)
ap_lda <- LDA(test , k = 4, control = list(seed = 1234))
ap_lda
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
bigrams_data <- unique_data %>%
mutate(Publication.Year = as.character(unique_data$Publication.Year))%>%
filter(Item.Type != "bookSection") %>%
select(Publication.Year, Author, Title,  DOI, Abstract.Note, Relevant)%>%
unnest_tokens(bigram, Title, token = "ngrams", n = 2) %>%
filter(!is.na(bigram))
bigrams_data %>%
count(bigram, sort = TRUE)
bigrams_separated <- bigrams_data %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_filtered <- bigrams_separated %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
# new bigram counts:
bigram_counts <- bigrams_filtered %>%
count(word1, word2, sort = TRUE)
data(stop_words)
bigram_counts
bigrams_united <- bigrams_filtered %>%
unite(bigram, word1, word2, sep = " ")
bigrams_united
View(bigrams_united)
unique_data() %>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram)) %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE)
# Trigrams, if needed
unique_data %>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram)) %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE)
# Trigrams, if needed
trigrams_filtered = unique_data %>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram)) %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE)
trigrams_united <- trigrams_filtered %>%
unite(bigram, word1, word2, word3, sep = " ")
View(trigrams_united)
# Trigrams, if needed
trigrams_filtered = unique_data %>%
mutate(Publication.Year = as.character(unique_data$Publication.Year))%>%
filter(Item.Type != "bookSection") %>%
select(Publication.Year, Author, Title,  DOI, Abstract.Note, Relevant)%>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram)) %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE)
trigrams_united <- trigrams_filtered %>%
unite(bigram, word1, word2, word3, sep = " ")
View(trigrams_united)
bigrams_data <- unique_data %>%
mutate(Publication.Year = as.character(unique_data$Publication.Year))%>%
filter(Item.Type != "bookSection") %>%
select(Publication.Year, Author, Title,  DOI, Abstract.Note, Relevant)%>%
unnest_tokens(bigram, Title, token = "ngrams", n = 2) %>%
filter(!is.na(bigram))
View(bigrams_data)
trigrams_filtered = unique_data %>%
mutate(Publication.Year = as.character(unique_data$Publication.Year))%>%
filter(Item.Type != "bookSection") %>%
select(Publication.Year, Author, Title,  DOI, Abstract.Note, Relevant)%>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram))
View(trigrams_filtered)
trigrams_filtered = trigrams%>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE)
# Trigrams, if needed
trigrams = unique_data %>%
mutate(Publication.Year = as.character(unique_data$Publication.Year))%>%
filter(Item.Type != "bookSection") %>%
select(Publication.Year, Author, Title,  DOI, Abstract.Note, Relevant)%>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram))
trigrams_filtered = trigrams%>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE)
trigrams_filtered
trigrams_filtered = trigrams%>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE) %>%
unite(bigram, word1, word2, word3, sep = " ")
View(trigrams_filtered)
trigrams_filtered = trigrams%>%
separate(trigram, c("word1", "word2", "word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE) %>%
unite(trigrams, word1, word2, word3, sep = " ")
names(trigrams_filtered)
bigrams_filtered
names(bigrams_separated)
# Trigrams, if needed
trigrams = unique_data %>%
mutate(Publication.Year = as.character(unique_data$Publication.Year))%>%
filter(Item.Type != "bookSection") %>%
select(Publication.Year, Author, Title,  DOI, Abstract.Note, Relevant)%>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram))
trigrams_separated <- trigrams %>%
separate(bigram, c("word1", "word2", "word3"), sep = " ")
trigrams_separated <- trigrams %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ")
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
count(word1, word2, word3, sort = TRUE) %>%
unite(trigrams, word1, word2, word3, sep = " ")
trigrams_filtered
# new trigram counts:
trigram_counts <- trigrams_filtered %>%
count(word1, word2, word3, sort = TRUE)
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
unite(trigrams, word1, word2, word3, sep = " ")
rlang::last_error()
trigrams_separated <- trigrams %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ")
names(trigrams_separated)
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
unite(trigrams, word1, word2, word3, sep = " ")
names(trigrams_filtered)
# Trigrams
trigrams = unique_data %>%
mutate(Publication.Year = as.character(unique_data$Publication.Year))%>%
filter(Item.Type != "bookSection") %>%
select(Publication.Year, Author, Title,  DOI, Abstract.Note, Relevant)%>%
unnest_tokens(trigram, Title, token = "ngrams", n = 3) %>%
filter(!is.na(trigram))
trigrams_separated <- trigrams %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ")
data(stop_words)
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
unite(trigrams, word1, word2, word3, sep = " ")
trigrams_filtered
names(trigrams_filtered)
bigrams_filtered %>%
filter(word2 == "health") %>%
count(Publication.Year, word2, sort = TRUE)
trigrams_filtered %>%
filter(word2 == "health") %>%
count(Publication.Year, word2, sort = TRUE)
trigrams_separated %>%
filter(word2 == "health") %>%
count(Publication.Year, word2, sort = TRUE)
trigrams_separated %>%
filter(word1 == "health") %>%
count(Publication.Year, word2, sort = TRUE)
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
mutate(trigrams = unite(trigrams, word1, word2, word3, sep = " "))
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
mutate(trigrams = unite(trigrams, word1, word2, word3, sep = " "))
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word) %>%
unite(trigrams, word1, word2, word3, sep = " ")
trigrams_filtered
names(trigrams_filtered)
trigrams_filtered <- trigrams_separated %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!word3 %in% stop_words$word)
trigrams_united = trigrams_filtered %>%
unite(trigrams, word1, word2, word3, sep = " ")
trigrams_filtered %>%
filter(word1 == "health") %>%
count(Publication.Year, word2, sort = TRUE)
trigrams_filtered[1:10,] %>%
filter(word1 == "health") %>%
count(Publication.Year, word2, sort = TRUE)
trigrams_filtered %>%
filter(word1 == "health") %>%
count(Publication.Year, word2, sort = TRUE)%>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_separated %>%
filter(word2 == "health") %>%
count(Publication.Year, word3, sort = TRUE) %>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word2 == "health") %>%
count(Publication.Year, word3, sort = TRUE) %>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word1 == "health") %>%
count(Publication.Year, word2, sort = TRUE)%>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word2 == "health") %>%
count(Publication.Year, word3, sort = TRUE) %>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word1 == "health") %>%
count( word2, sort = TRUE)%>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word2 == "health") %>%
count(word3, sort = TRUE) %>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word3 == "health") %>%
count(word3, sort = TRUE) %>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word1 == "health") %>%
count(word3, sort = TRUE) %>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_filtered %>%
filter(word1 == "health") %>%
count(word2, sort = TRUE)%>%
# Do the count but by year count(Publication.Year, word2, sort = TRUE) %>%
arrange(desc(n)) %>%
slice_head(n = 5)
trigrams_united = trigrams_filtered %>%
unite(trigrams, word1, word2, word3, sep = " ")
head(trigrams_united)
names(trigrams_united)
trigram_tf_idf <- trigrams_united %>%
count(Publication.Year, trigrams) %>%
bind_tf_idf(trigrams, Publication.Year, n) %>%
arrange(desc(tf_idf))
names(trigram_tf_idf)
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf_idf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(trigrams, tf_idf), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
trigram_tf_idf
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf_idf, n = 5)
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf_idf, n = 5) %>%
ungroup()
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf_idf, n = 5) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(trigrams, tf_idf), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf_idf, n = 5) %>%
ungroup()
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_max(tf_idf, n = 4) %>%
ungroup()
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_head(tf_idf, n = 4) %>%
ungroup()
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_head(n = 4) %>%
ungroup()
trigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_head(n = 4) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(trigrams, tf_idf), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
names(trigram_tf_idf)
# Total frequency
trigram_tf_idf %>%
arrange(desc(n)) %>%
group_by(Publication.Year) %>%
slice_head(n = 4) %>%
ungroup() %>%
ggplot(aes(n, fct_reorder(trigrams, n), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "n", y = NULL)
bigram_tf_idf <- bigrams_united %>%
count(Publication.Year, trigrams) %>%
bind_tf_idf(trigrams, Publication.Year, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf <- bigrams_united %>%
count(Publication.Year, trigrams) %>%
bind_tf_idf(bigram, Publication.Year, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf <- bigrams_united %>%
count(Publication.Year, bigram) %>%
bind_tf_idf(bigram, Publication.Year, n) %>%
arrange(desc(tf_idf))
bigram_tf_idf %>%
group_by(Publication.Year) %>%
slice_head(n = 4) %>%
ungroup() %>%
ggplot(aes(tf_idf, fct_reorder(bigram, tf_idf), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "tf-idf", y = NULL)
# Total frequency
bigram_tf_idf %>%
arrange(desc(n)) %>%
group_by(Publication.Year) %>%
slice_head(n = 4) %>%
ungroup() %>%
ggplot(aes(n, fct_reorder(bigram, n), fill = Publication.Year)) +
geom_col(show.legend = FALSE) +
facet_wrap(~Publication.Year, ncol = 2, scales = "free") +
labs(x = "n", y = NULL)
bigram_graph <- bigram_counts %>%
filter(n > 20) %>%
graph_from_data_frame()
install.packages("igraph")
library(igraph)
bigram_graph <- bigram_counts %>%
filter(n > 20) %>%
graph_from_data_frame()
library(ggraph)
install.packages(ggraph)
install.packages("ggraph")
library("ggraph")
library(ggraph)
set.seed(2017)
ggraph(bigram_graph, layout = "fr") +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = name), vjust = 1, hjust = 1)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
ggraph(bigram_graph, layout = "fr") +
geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
arrow = a, end_cap = circle(.07, 'inches')) +
geom_node_point(color = "lightblue", size = 5) +
geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
theme_void()
devtools::install_github("rstudio/rmarkdown")
install.packages("devtools")
devtools::install_github("rstudio/rmarkdown")
devtools::install_github("rstudio/rmarkdown")
library("rstudio/rmarkdown")
library(prettydoc)
unlink("Text Analysis_cache", recursive = TRUE)
detach("xfun")
detach("package:xfun")
?xfun
??xfun
detach("package:xfun", unload=TRUE)
install.packages("xfun")
install.packages("xfun")
install.packages("xfun")
library(topicmodels)
library(xfun)
library(topicmodels)
detach("package:xfun", unload = TRUE)
library(xfun)
remove.packages("xfun")
library(xfun)
install.packages("xfun")
install.packages("xfun")
library(xfun)
library(xfun)
knit_with_parameters("C:/Users/Sebastian/OneDrive/UBC/Work for Monique/Text Analysis/Text Analysis.Rmd")
unlink("Text Analysis_cache", recursive = TRUE)
library(prettydoc)
title: "Visualizing Themes in Research About Refugee Children"
